{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginner Tutorials\n",
    "=========================\n",
    "Deep Learning with PyTorch: A 60 Minute Blitz\n",
    "1. What is Pytorch?\n",
    "2. Autograd: automatic differentiation\n",
    "\n",
    "Offical Tutorial: http://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00  4.6566e-10  0.0000e+00\n",
      " 4.6566e-10  7.0065e-45  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  0.0000e+00  0.0000e+00\n",
      " 0.0000e+00  4.6566e-10  1.4056e+19\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a 5x3 matrix, uninitialized:\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.8189  0.0683  0.1503\n",
      " 0.7245  0.7786  0.0010\n",
      " 0.3036  0.9990  0.9381\n",
      " 0.7206  0.0548  0.0544\n",
      " 0.7824  0.4603  0.7370\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Construct a randomly initialized matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "#Get its size\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0584  0.1774  0.4190\n",
      " 0.9472  0.7884  0.5139\n",
      " 0.9094  1.1269  1.3849\n",
      " 1.3752  0.1708  0.6746\n",
      " 0.9727  1.3338  1.1383\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 相加\n",
    "y = torch.rand(5,3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0584  0.1774  0.4190\n",
      " 0.9472  0.7884  0.5139\n",
      " 0.9094  1.1269  1.3849\n",
      " 1.3752  0.1708  0.6746\n",
      " 0.9727  1.3338  1.1383\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 相加\n",
    "print(torch.add(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0584  0.1774  0.4190\n",
      " 0.9472  0.7884  0.5139\n",
      " 0.9094  1.1269  1.3849\n",
      " 1.3752  0.1708  0.6746\n",
      " 0.9727  1.3338  1.1383\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#giving an output tensor\n",
    "result = torch.Tensor(5,3)\n",
    "torch.add(x,y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0584  0.1774  0.4190\n",
      " 0.9472  0.7884  0.5139\n",
      " 0.9094  1.1269  1.3849\n",
      " 1.3752  0.1708  0.6746\n",
      " 0.9727  1.3338  1.1383\n",
      "[torch.FloatTensor of size 5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# in-place\n",
    "# adds x to y\n",
    "# y被改變成原本的y+x \n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.0584\n",
      " 0.9472\n",
      " 0.9094\n",
      " 1.3752\n",
      " 0.9727\n",
      "[torch.FloatTensor of size 5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting tensors to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5,2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# torch 轉 numpy\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2  2\n",
      " 2  2\n",
      " 2  2\n",
      " 2  2\n",
      " 2  2\n",
      "[torch.FloatTensor of size 5x2]\n",
      "\n",
      "[[ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]\n",
      " [ 2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting numpy Array to torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 4]\n",
      " [2 5]]\n",
      "\n",
      " 2  4\n",
      " 2  5\n",
      "[torch.LongTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numpy 轉 torch\n",
    "import numpy as np\n",
    "a = np.array([[1,3], [1,4]])\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have nvidia GPU\n",
    "# let us run this cell only if CUDA is available\n",
    "# 判斷電腦是否支持GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch的自動求導功能\n",
    "===============================\n",
    "- torch 和大部分框架一樣有自動求導功能，但對象不再是 torch.Tensor，而是 torch.autograd.Variable\n",
    "- 本質上 Variable 和 Tensor 沒有什麼區別，不過Variable會放在一個計算圖裡面，可以進行前向傳播和反向傳播以及求導數\n",
    "- grad 表示反向傳播的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad 表示是否對其求梯度，預設是false\n",
    "x = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "y = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "z = 2 * x + y + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對X,Y分別求導數\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "dz/dy:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X,Y 的導數\n",
    "print(\"dz/dx:{}\".format(x.grad.data))\n",
    "print(\"dz/dy:{}\".format(y.grad.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神經網絡部分\n",
    "========\n",
    "- 所依賴的主要是 torch.nn 和 torch.nn.functional\n",
    "- torch.nn裡面有所有神經網絡的層的操作，其用來建構網絡，只有執行一次網絡的運算才執行一次\n",
    "- torch.nn.functional 表示的是直接對其做一次向前運算操作\n",
    "- 官方文檔：http://pytorch.org/docs/master/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net_name(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net_name, self).__init__() # 運行nn.module的初始化函數     \n",
    "        # 可以添加各種網絡層\n",
    "        self.convl = nn.Conv2d(3,10,3)   # 輸入為3張圖像，輸出為10張特徵圖，卷積核為3X3正方形\n",
    "        # 具體每種層的參數可以再去查看文檔\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 定義向前傳播\n",
    "        out = self.convl(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv3",
   "language": "python",
   "name": "pyenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
